{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "In this notebook is implemented the three experiments described in the paper.\n",
    "\n",
    "## Header\n",
    "\n",
    "Libraries and additional programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import random\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [12,9]\n",
    "\n",
    "pathh = '../Data/' \n",
    "#exp_file = 'ExperimentalResults_2.xlsx'  #Datos obtenidos con mis encuestas\n",
    "#exp_file = 'ExperimentalResults_3.xlsx'   # Datos de MTURK-771\n",
    "exp_file = '../Data/ExperimentalResults_4.xlsx'   # Q1 Modificado..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing memory and encoding dataset in HD space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of memory initialization\n",
      "Begining to encode dataset...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-137-37b4c73b4ac0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'run EncodingDataset.ipynb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mInit_mem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-137-9cc1bb76fc0a>\u001b[0m in \u001b[0;36mInit_mem\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mthr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.45\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Read dataset and create definition dictionary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mCreateDictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;31m# Feature vectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mFeatureVectors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDict_defs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-137-d18b0c6b5a33>\u001b[0m in \u001b[0;36mCreateDictionary\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mReadDefinitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mconcept\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mDict_defs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconcept\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTranslateFeats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcept\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-137-d678489e9963>\u001b[0m in \u001b[0;36mTranslateFeats\u001b[1;34m(ListFeat)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;34m\"It receives a list of features such as ['is_blue', 'is_rectangular'] and it returns: [['color','blue'], ['shape','rectangular']\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Dataframe for excel document\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpathh\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'FEATS_brm.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#../McRaedataset/FEATS_brm.xlsx')\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mListPairs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfeat\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mListFeat\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jobqu\\Anaconda2\\lib\\site-packages\\pandas\\util\\_decorators.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jobqu\\Anaconda2\\lib\\site-packages\\pandas\\io\\excel.pyc\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, skiprows, skip_footer, index_col, names, usecols, parse_dates, date_parser, na_values, thousands, convert_float, converters, dtype, true_values, false_values, engine, squeeze, **kwds)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     return io._parse_excel(\n",
      "\u001b[1;32mC:\\Users\\jobqu\\Anaconda2\\lib\\site-packages\\pandas\\io\\excel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, io, **kwds)\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m             raise ValueError('Must explicitly set engine if not passing in'\n",
      "\u001b[1;32mC:\\Users\\jobqu\\Anaconda2\\lib\\site-packages\\xlrd\\__init__.pyc\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[0;32m    141\u001b[0m                 \u001b[0mformatting_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformatting_info\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m                 \u001b[0mon_demand\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_demand\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m                 \u001b[0mragged_rows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mragged_rows\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m                 )\n\u001b[0;32m    145\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mbk\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jobqu\\Anaconda2\\lib\\site-packages\\xlrd\\xlsx.pyc\u001b[0m in \u001b[0;36mopen_workbook_2007_xml\u001b[1;34m(zf, component_names, logfile, verbosity, use_mmap, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msst_fname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcomponent_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m         \u001b[0mzflo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomponent_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msst_fname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m         \u001b[0mx12sst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzflo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SST'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mzflo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jobqu\\Anaconda2\\lib\\site-packages\\xlrd\\xlsx.pyc\u001b[0m in \u001b[0;36mprocess_stream_iterparse\u001b[1;34m(self, stream, heading)\u001b[0m\n\u001b[0;32m    430\u001b[0m         \u001b[0melemno\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m         \u001b[0msst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sharedstrings\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mET\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0msi_tag\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0melemno\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melemno\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<string>\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run EncodingDataset.ipynb\n",
    "Init_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1\n",
    "\n",
    "Given a concept it retrieves the \"num_concepts\" most similar concepts to it (for each different method). A comparison between methods is done by counting the number of coincidences between lists of concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "# List of all concepts in dataset\n",
    "Concepts = get_concepts_list() \n",
    "\n",
    "# Test concepts\n",
    "sample_size = 10\n",
    "#Test_Concepts = random.sample(Concepts, sample_size)\n",
    "Test_Concepts =  ['spoon'] #, 'airplane', 'chair']\n",
    "print Test_Concepts\n",
    "\n",
    "num_concepts = 11\n",
    "coincidence = []\n",
    "\n",
    "for test_concept in Test_Concepts:\n",
    "    print \"\\n\\nConcept: \", test_concept\n",
    "    # Asking closest concept of another concept's definition...\n",
    "    HDC_sim = HDvector.getLabelSP(Dict[test_concept].getPointer())[:num_concepts]\n",
    "    HDC_sim = NormalizeHammDist(HDC_sim)\n",
    "    print \"HDC_sim: \", HDC_sim\n",
    "    \n",
    "    DatSet_sim = ClosestConcepts(test_concept, num_concepts)\n",
    "    print \"DatSet_sim: \", DatSet_sim\n",
    "\n",
    "    concept = wn.synset( get_synset(test_concept) )\n",
    "    # Path similarity\n",
    "    LC_sim = apply_sim_metric(wn.lch_similarity, num_concepts, concept ) \n",
    "    print \"LC_sim: \", LC_sim\n",
    "    WUP_sim = apply_sim_metric(wn.wup_similarity, num_concepts, concept )\n",
    "    print \"WUP_sim: \", WUP_sim\n",
    "    \n",
    "    # Information Content\n",
    "    Res_sim = apply_sim_metric(wn.res_similarity, num_concepts, concept, brown_ic)\n",
    "    print \"Res_sim: \", Res_sim\n",
    "    JC_sim = apply_sim_metric(wn.jcn_similarity, num_concepts, concept, brown_ic)\n",
    "    print \"JC_sim: \", JC_sim\n",
    "    \n",
    "    # Comparing lists agains HDC_sim for counting coincidence.\n",
    "    # Creating name sets\n",
    "    HDC_names = set([x[0] for x in HDC_sim])\n",
    "    DatSet_names = set([x[0] for x in DatSet_sim])\n",
    "    LC_names = set([x[0] for x in LC_sim])\n",
    "    WUP_names = set([x[0] for x in WUP_sim])\n",
    "    Res_names = set([x[0] for x in Res_sim])\n",
    "    JC_names = set([x[0] for x in JC_sim])\n",
    "    \n",
    "    coincidence = coincidence + [[len(HDC_names.intersection(DatSet_names)), \n",
    "                                 len(HDC_names.intersection(LC_names)), \n",
    "                                 len(HDC_names.intersection(WUP_names)),    \n",
    "                                 len(HDC_names.intersection(Res_names)), \n",
    "                                 len(HDC_names.intersection(JC_names))]]\n",
    "    print coincidence\n",
    "\n",
    "coincidence = np.array(coincidence)\n",
    "# Measuring average against each method.\n",
    "print \"Average: \", np.mean(coincidence, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2\n",
    "\n",
    "### a) Human-judged similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ListofPairs (number):\n",
    "    \"It obtains a list of pairs of concepts\"\n",
    "    df = pd.read_excel(exp_file)\n",
    "    if number > 0:\n",
    "        string = 'Q' + str(number)    \n",
    "    else:\n",
    "        string = 'average'\n",
    "    # 1) List of concepts\n",
    "    ordered = df.sort_values(by=string)\n",
    "    c1 = map(str, list( ordered['concept 1'] ))\n",
    "    c2 = map(str, list( ordered['concept 2'] ))\n",
    "    L1 = map(list, zip(c1,c2))\n",
    "    \n",
    "    # 2) Human similarity and stdev\n",
    "    ordered = df.sort_values(by=string)\n",
    "    L2 = list(ordered[string])\n",
    "    L3 = list(ordered['stdev'])\n",
    "    return L1, L2, L3\n",
    "\n",
    "PConcepts, Hum_Sim, stdev = ListofPairs(1)\n",
    "\n",
    "\n",
    "x = np.array(range(64))\n",
    "stdev = np.array(map(lambda x: x*0.5, stdev))\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [11,7]\n",
    "\n",
    "line,caps,bars = plt.errorbar(x, Hum_Sim, stdev,       \n",
    "                    fmt=\"k-\",\n",
    "                    #linestyle='None',\n",
    "                    marker='.',\n",
    "                    markersize=5,\n",
    "                    linewidth=0.3,\n",
    "                    elinewidth=0.5,\n",
    "                    ecolor='k',\n",
    "                    capsize=3,\n",
    "                    capthick=1.2)\n",
    "\n",
    "# plt.setp(bars,label=\"Std dev\")\n",
    "# plt.legend(loc=('upper left'), prop={'size': 15})\n",
    "plt.xlim((0,64))\n",
    "plt.xlabel('Pair number', fontsize=18)\n",
    "plt.ylabel('Semantic similarity', fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.savefig('HumSim.png', dpi=300)\n",
    "#plt.errorbar(x, Hum_Sim, stdev, linestyle='None', marker='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Measuring similarity\n",
    "\n",
    "In this cell we measure the similarity of each pair of concepts with each similarity measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of distances for each method\n",
    "Dict_HD = {}; Dict_McRae = {}; Dict_wup = {}; Dict_lch = {}; Dict_res = {}; Dict_jcn = {}\n",
    "\n",
    "# Loop over all pairs of concepts\n",
    "key = 0\n",
    "print \"Starting\"\n",
    "for pair in PConcepts:\n",
    "    print key,\n",
    "    Dict_HD[key] = 1. - HDvector.dist(Dict[pair[0]].getPointer(), Dict[pair[1]].getPointer()) / float(N)\n",
    "    Dict_McRae[key] = McRae_simi(pair)\n",
    "    Dict_wup[key] = similarity_fun(wn.wup_similarity, pair)\n",
    "    Dict_lch[key] = similarity_fun(wn.lch_similarity, pair)\n",
    "    Dict_res[key] = similarity_fun(wn.res_similarity, pair, brown_ic)\n",
    "    Dict_jcn[key] = similarity_fun(wn.jcn_similarity, pair, brown_ic)\n",
    "    key += 1\n",
    "print \"End\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Computing correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1) Obtain \"human list\", it can be the average responses or an specific one\n",
    "Hum_sim =  ListofPairs(3) #or Q + #0-30\n",
    "    \n",
    "# 2) Obtain list of ordered concepts (keys)\n",
    "keys = map(lambda x: PConcepts.index(x), Hum_sim[0])\n",
    "    \n",
    "# 3) Create a list of distances according to each metric by consulting the appropiate dictionary\n",
    "HD_sim = [Dict_HD[x] for x in keys]\n",
    "McRae_sim = [Dict_McRae[x] for x in keys]\n",
    "wup_sim = [Dict_wup[x] for x in keys]\n",
    "lch_sim = [Dict_lch[x] for x in keys]\n",
    "res_sim = [Dict_res[x] for x in keys]\n",
    "jcn_sim = [Dict_jcn[x] for x in keys]\n",
    "\n",
    "# 4) Calculate correlations\n",
    "correlations = [['HDC', pearsonr(Hum_sim[1], HD_sim)[0]], ['McRae', pearsonr(Hum_sim[1], McRae_sim)[0]],\n",
    "                ['wup', pearsonr(Hum_sim[1], wup_sim)[0]], ['lch', pearsonr(Hum_sim[1], lch_sim)[0]],\n",
    "                ['res', pearsonr(Hum_sim[1], res_sim)[0]], ['jcn', pearsonr(Hum_sim[1], jcn_sim)[0]]]\n",
    "\n",
    "print correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.rcParams[\"figure.figsize\"] = [16,12]\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "plt.subplot(321)\n",
    "plt.plot(HD_sim, color='k', linestyle='None', marker='x', markersize=5, linewidth=1 )  \n",
    "\n",
    "plt.title('HDC')\n",
    "plt.xlabel('Pair number', fontsize=12)\n",
    "plt.ylabel('Semantic similarity', fontsize=12)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(322)\n",
    "plt.plot(res_sim, color='k', linestyle='None', marker='.', markersize=5, linewidth=1 )  \n",
    "plt.title('Resnik')\n",
    "plt.xlabel('Pair number', fontsize=12)\n",
    "plt.ylabel('Semantic similarity', fontsize=12)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(323)\n",
    "plt.plot(McRae_sim, color='k', linestyle='None', marker='^', markersize=5, linewidth=1 )  \n",
    "plt.title('McRae')\n",
    "plt.xlabel('Pair number', fontsize=12)\n",
    "plt.ylabel('Semantic similarity', fontsize=12)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(324)\n",
    "plt.plot(jcn_sim, color='k', linestyle='None', marker='+', markersize=4, linewidth=1 )  \n",
    "plt.title('Jiang & Conrath')\n",
    "plt.xlabel('Pair number', fontsize=12)\n",
    "plt.ylabel('Semantic similarity', fontsize=12)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(325)\n",
    "plt.plot(lch_sim, color='k', linestyle='None', marker='*', markersize=4, linewidth=1 )  \n",
    "plt.title('Leacock & Chodorow')\n",
    "plt.xlabel('Pair number', fontsize=12)\n",
    "plt.ylabel('Semantic similarity', fontsize=12)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(326)\n",
    "plt.plot(wup_sim, color='k', linestyle='None', marker='.', markersize=5, linewidth=1 )  \n",
    "plt.title('Wu & Palmer')\n",
    "plt.xlabel('Pair number', fontsize=12)\n",
    "plt.ylabel('Semantic similarity', fontsize=12)\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "plt.savefig('SubPlots.png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
