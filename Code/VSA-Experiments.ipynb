{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "This notebook contains several experiments for encoding high-dimensional vectors representing concepts. The concept's definitions rely on a set of semantic features obtained from a dataset collected by McRae et al. \n",
    "\n",
    "This notebook uses the functions declared in HDComputingbasics and EncodingDataset to create and compare vector representations. \n",
    "\n",
    "## Header\n",
    "\n",
    "Libraries and additional programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import random\n",
    "from scipy.stats.stats import pearsonr, spearmanr\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [12,9]\n",
    "\n",
    "pathh = '../Data/'\n",
    "exp_file = '../Data/Human_Similarity.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing memory and encoding dataset in HD space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of memory initialization\n",
      "Begining to encode dataset...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"dict_keys\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-af90d213b7a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'run'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'EncodingDataset.ipynb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mInit_mem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-4b353db34847>\u001b[0m in \u001b[0;36mInit_mem\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mFeatureVectors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDict_defs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# Save concepts into memory (ID vectors)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mSaveConcepts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDict_defs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Associate definitions to concepts into memory (SP vectors)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mSaveDefinitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDict_defs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-342313dfd752>\u001b[0m in \u001b[0;36mSaveConcepts\u001b[1;34m(Dic)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mDic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mall_concepts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[1;31m# Process for storing list of concepts in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mconcept\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_concepts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate list (not \"dict_keys\") to list"
     ]
    }
   ],
   "source": [
    "%run EncodingDataset.ipynb\n",
    "Init_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept similarity\n",
    "\n",
    "### a) Human-judged similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ListofPairs ( ):\n",
    "    \"It obtains the list of concept pairs rated by Humans\"\n",
    "    df = pd.read_excel(exp_file)\n",
    "    ordered = df.sort_values(by='Sim')\n",
    "    c1 = map(str, list( ordered['concept 1'] ))\n",
    "    c2 = map(str, list( ordered['concept 2'] ))\n",
    "    L1 = map(list, zip(c1,c2))\n",
    "    # Sorting by value\n",
    "    ordered = df.sort_values(by='Sim')\n",
    "    L2 = list(ordered['Sim'])\n",
    "    return L1, L2\n",
    "\n",
    "PConcepts, Hum_Sim = ListofPairs()\n",
    "\n",
    "x = np.array(range(64))\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [12,8]\n",
    "\n",
    "plt.plot(Hum_Sim, color='k', linestyle='-', marker='.', markersize=6, linewidth=.3 )  \n",
    "plt.xlim((0,64))\n",
    "plt.xlabel('Numero de Pareja', fontsize=18)\n",
    "plt.ylabel('Similitud semantica', fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.savefig('HumSim.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Measuring similarity\n",
    "\n",
    "In this cell we measure the similarity of each pair of concepts with each similarity measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of distances for each method\n",
    "Dict_HD = {}; Dict_McRae = {}; Dict_wup = {}; Dict_lch = {}; Dict_res = {}; Dict_jcn = {}; Dict_GlossOverlap = {}\n",
    "\n",
    "# Loop over all pairs of concepts\n",
    "key = 0\n",
    "print(\"Starting\")\n",
    "for pair in PConcepts:\n",
    "    print(key)\n",
    "    # VSA\n",
    "    Dict_HD[key] = 1. - HDvector.dist(Dict[pair[0]].getPointer(), Dict[pair[1]].getPointer()) / float(N)\n",
    "    # McRae\n",
    "    Dict_McRae[key] = McRae_simi(pair)\n",
    "    # Wu & Palmer\n",
    "    Dict_wup[key] = similarity_fun(wn.wup_similarity, pair)\n",
    "    # Leacock & Chodorow\n",
    "    Dict_lch[key] = similarity_fun(wn.lch_similarity, pair)\n",
    "    # Resnik\n",
    "    Dict_res[key] = similarity_fun(wn.res_similarity, pair, brown_ic)\n",
    "    # Jiang & Conrad\n",
    "    Dict_jcn[key] = similarity_fun(wn.jcn_similarity, pair, brown_ic)\n",
    "    # Newly added: Extended gloss overlaps\n",
    "    Dict_GlossOverlap[key] = similarity_fun(GlossRelatedness, pair)\n",
    "    key += 1\n",
    "print(\"End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pirró & Euzenat relatedness measure\n",
    "\n",
    "For the FaITH measure we obtained the similarity value for each pair from the \"Java WordNet Similarity Library\". This code was kindly shared by Giuseppe Pirró upon request. \n",
    "\n",
    "For more information on this library visit: https://simlibrary.wordpress.com/obtaining-the-similarity-library/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Faith_rel = [0.775212021177373,  0.15923558025435458,  0.8170208828537676,  0.33853972249476155, 0.7861997148711021,  0.004810182852762178,\n",
    "         0.0046200348878155835, 0.763822248978457, 0.6096878654007747, 0.7777645490911547, 0.1659469335590268, 0.7110415588155834, 0.5272439906799019,\n",
    "          0.5903398679327476, 0.1636359503568791, 0.6088308713691877, 0.4535672918360572, 0.4930226138395317, 0.4883801316451221,\n",
    "          0.1308130631823140, 0.6044051786969269, 0.14210674386294322, 0.7889246781173663, 0.5899396720164379, 0.5833700708914448,\n",
    "          0.4881518657711761, 0.48360023654391676, 0.30092775623250656, 0.5646663492871861, 0.5602506937986234, 0.5538081921326253,\n",
    "          0.33888995243923614, 0.4841257163131293, 0.1534360344880267, 0.49239548449468856, 0.03442139006134628, 0.4686020159254125,\n",
    "          0.004394779331623425, 0.1690345073141489, 0.5066022372200712, 0.48428237458481754, 0.12004335318053518, 0.18758569399764846,\n",
    "          0.4702235163724711, 0.1942883150689591, 0.19002694046815294, 0.03442139006134628, 0.15191873168381645, 0.19015556730231345,\n",
    "          0.1386688283590378, 0.004862268365414031, 0.1375312433803571, 0.0049279262556529944, 0.17633443880493346, 0.1985541588059305,\n",
    "          0.5069208157880991, 0.274349305987516, 0.005261997333713331, 0.4702235163724711, 0.31489545741456226, 0.17427498355437368,\n",
    "          0.004740377540793999, 0.36091724276902865, 0.4702235163724711]\n",
    "\n",
    "Faith_rel.reverse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2vec\n",
    "\n",
    "The word2vec similarity values were obtained by using the online model GoogleNews Negative 300 located in:\n",
    "http://bionlp-www.utu.fi/wv_demo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wor2vec = [0.8266455382108688, 0.8415886908769608, 0.6807796359062195, 0.8549512177705765, 0.7889042645692825,0.7572457492351532, 0.9644697681069374,\n",
    " 0.9086581096053123, 0.721133679151535, 0.798522099852562, 0.6787266135215759, 0.647223562002182, 0.8754299804568291, 0.7132392525672913, 0.5137060284614563,\n",
    " 0.7079006731510162, 0.7908777445554733, 0.6040608584880829, 0.7750198692083359, 0.8645816594362259, 0.801501139998436, 0.8661240190267563, 0.9446705915033817,\n",
    " 0.7778908014297485,0.7617271989583969, 0.9460270218551159, 0.6787038743495941, 0.6298098266124725, 0.34256309270858765, 0.5335637629032135, 0.425468385219574,\n",
    " 0.6396835148334503, 0.7532171458005905, 0.6008948087692261, 0.6555060744285583, 0.8036634474992752, 0.6344016194343567, 0.5572055578231812,\n",
    " 0.5680522620677948, 0.6650005877017975, 0.7124116122722626, 0.8490201681852341, 0.4361061453819275, 0.7542188316583633, 0.7908401340246201, 0.6777022778987885,\n",
    " 0.7414279878139496, 0.6713162362575531, 0.6733077168464661, 0.4685635566711426, 0.696144700050354,0.4178849458694458, 0.4083590507507324, 0.3246746063232422, \n",
    " 0.8281060010194778, 0.4699099063873291, 0.5488384962081909, 0.4087533950805664, 0.2889356017112732, 0.5542740821838379, 0.34602856636047363, 0.8630458861589432,\n",
    " 0.3001639246940613, 0.5954327881336212]\n",
    "\n",
    "# Getting similarity instead of distance\n",
    "wor2vec = map(lambda x: 1-x, wor2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Computing correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1) Obtain \"human list\", it can be the average responses or an specific one\n",
    "Hum_sim =  ListofPairs( )  #or Q + #0-30\n",
    "    \n",
    "# 2) Obtain list of ordered concepts (keys)\n",
    "keys = map(lambda x: PConcepts.index(x), Hum_sim[0])\n",
    "    \n",
    "# 3) Create a list of distances according to each metric by consulting the appropiate dictionary\n",
    "HD_simm = [Dict_HD[x] for x in keys]\n",
    "HD_sim = map(lambda x: (x - min(HD_simm)) / (max(HD_simm) - min(HD_simm)), HD_simm) \n",
    "\n",
    "McRae_simm = [Dict_McRae[x] for x in keys]\n",
    "McRae_sim = map(lambda x: (x - min(McRae_simm)) / (max(McRae_simm) - min(McRae_simm)), McRae_simm) \n",
    "\n",
    "wup_simm = [Dict_wup[x] for x in keys]\n",
    "wup_sim = map(lambda x: (x - min(wup_simm)) / (max(wup_simm) - min(wup_simm)), wup_simm) \n",
    "\n",
    "lch_simm = [Dict_lch[x] / 2.944 for x in keys]\n",
    "lch_sim = map(lambda x: (x - min(lch_simm)) / (max(lch_simm) - min(lch_simm)), lch_simm) \n",
    "\n",
    "res_simm = [Dict_res[x] / 10.574 for x in keys] # / max\n",
    "res_sim = map(lambda x: (x - min(res_simm)) / (max(res_simm) - min(res_simm)), res_simm) \n",
    "\n",
    "jcn_simm = [Dict_jcn[x] for x in keys]\n",
    "jcn_sim = map(lambda x: (x - min(jcn_simm)) / (max(jcn_simm) - min(jcn_simm)), jcn_simm) \n",
    "\n",
    "EGO_simm = [Dict_GlossOverlap[x] for x in keys]\n",
    "EGO_sim  = [x if x < 40 else 40 for x in EGO_simm]\n",
    "\n",
    "# 4) Calculate correlations\n",
    "correlations = [['HDC', spearmanr(Hum_sim[1], HD_sim)[0]], ['McRae', spearmanr(Hum_sim[1], McRae_sim)[0]],\n",
    "                ['wup', spearmanr(Hum_sim[1], wup_sim)[0]], ['lch', spearmanr(Hum_sim[1], lch_sim)[0]],\n",
    "                ['res', spearmanr(Hum_sim[1], res_sim)[0]], ['jcn', spearmanr(Hum_sim[1], jcn_sim)[0]],\n",
    "                ['Gloss', spearmanr(Hum_sim[1], EGO_sim)[0]], ['Faith', spearmanr(Hum_sim[1], Faith_rel)[0]], \n",
    "                ['word2vec', spearmanr(Hum_sim[1],wor2vec)[0]]]\n",
    "\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Plotting\n",
    "\n",
    "### Original & VSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [10, 6]\n",
    "# Human similarity\n",
    "plt.plot([x/10 for x in Hum_Sim], color='k', linestyle='-', marker='.', markersize=4, linewidth=.3 )  \n",
    "# VSA\n",
    "plt.plot(HD_sim, color='k', linestyle='None', marker='x', markersize=7, linewidth=1 )  \n",
    "plt.xlabel('Numero de Pareja', fontsize=15)\n",
    "plt.ylabel('Similitud semantica', fontsize=15)\n",
    "plt.ylim(0,1)\n",
    "plt.grid(True)\n",
    "plt.legend(['Similitud estimada por humanos', 'Usando modelo VSA'], fontsize = 14)\n",
    "plt.savefig('Hum_VSA.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.rcParams[\"figure.figsize\"] = [18, 9]\n",
    "f_size = 12\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "# Human similarity\n",
    "plt.subplot(241)\n",
    "plt.plot([x/10 for x in Hum_Sim], color='k', linestyle='None', marker='.', markersize=6, linewidth=.3 )  \n",
    "plt.title('Benchmark', fontsize=f_size)\n",
    "plt.xlabel('Numero de Pareja', fontsize=f_size)\n",
    "plt.ylabel('Similitud semantica', fontsize=f_size)\n",
    "plt.ylim(0,1)\n",
    "plt.grid(True)\n",
    "plt.text(1, 0.5, '(a)', fontsize = 14)\n",
    "\n",
    "# VSA\n",
    "plt.subplot(242)\n",
    "plt.plot(HD_sim, color='k', linestyle='None', marker='x', markersize=7, linewidth=1 )  \n",
    "plt.title('VSA', fontsize=f_size)\n",
    "plt.xlabel('Numero de pareja', fontsize=f_size)\n",
    "#plt.ylabel('Similitud semantica', fontsize=f_size)\n",
    "plt.ylim(0,1)\n",
    "plt.grid(True)\n",
    "\n",
    "# McRae\n",
    "plt.subplot(243)\n",
    "plt.plot(McRae_sim, color='k', linestyle='None', marker='^', markersize=6, linewidth=1 )  \n",
    "plt.title('McRae', fontsize=f_size)\n",
    "plt.xlabel('Numero de pareja', fontsize=f_size)\n",
    "#plt.ylabel('Similitud semantica', fontsize=f_size)\n",
    "plt.ylim(0,1)\n",
    "plt.grid(True)\n",
    "\n",
    "# WuP\n",
    "plt.subplot(244)\n",
    "plt.plot(wup_sim, color='k', linestyle='None', marker='.', markersize=8, linewidth=1 )  \n",
    "plt.title('Wu & Palmer', fontsize=f_size)\n",
    "plt.xlabel('Numero de pareja', fontsize=f_size)\n",
    "#plt.ylabel('Similitud semantica', fontsize=f_size)\n",
    "plt.ylim(0,1)\n",
    "plt.grid(True)\n",
    "\n",
    "# LCH\n",
    "plt.subplot(245)\n",
    "plt.plot(lch_sim, color='k', linestyle='None', marker='*', markersize=7, linewidth=1 )  \n",
    "plt.title('Leacock & Chodorow', fontsize=f_size)\n",
    "plt.xlabel('Numero de pareja', fontsize=f_size)\n",
    "#plt.ylabel('Similitud semantica', fontsize=f_size)\n",
    "plt.ylim(0,1)\n",
    "plt.grid(True)\n",
    "\n",
    "# Resnick\n",
    "plt.subplot(246)\n",
    "plt.plot(res_sim, color='k', linestyle='None', marker='.', markersize=9, linewidth=1 )  \n",
    "plt.title('Resnik', fontsize=f_size)\n",
    "plt.xlabel('Numero de pareja', fontsize=f_size)\n",
    "#plt.ylabel('Similitud semantica', fontsize=f_size)\n",
    "plt.ylim(0,1)\n",
    "plt.grid(True)\n",
    "\n",
    "#JnC\n",
    "plt.subplot(247)\n",
    "plt.plot(jcn_sim, color='k', linestyle='None', marker='+', markersize=8, linewidth=1 )  \n",
    "plt.title('Jiang & Conrath', fontsize=f_size)\n",
    "plt.xlabel('Numero de pareja', fontsize=f_size)\n",
    "#plt.ylabel('Similitud semantica', fontsize=f_size)\n",
    "plt.ylim(0,1)\n",
    "plt.grid(True)\n",
    "\n",
    "# word2vec\n",
    "plt.subplot(248)\n",
    "plt.plot(wor2vec, color='k', linestyle='None', marker='.', markersize=7, linewidth=1 )  \n",
    "plt.title('word2vec', fontsize=f_size)\n",
    "plt.xlabel('Numero de pareja', fontsize=f_size)\n",
    "plt.ylabel('Similitud semantica', fontsize=f_size)\n",
    "plt.ylim(0,1)\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "plt.savefig('SubPlots.png', dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended gloss Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gloss Overlap\n",
    "plt.plot(EGO_sim, color='k', linestyle='None', marker='+', markersize=8, linewidth=1 )  \n",
    "plt.title('Extended Gloss Overlap', fontsize=f_size)\n",
    "plt.xlabel('Numero de pareja', fontsize=f_size)\n",
    "#plt.ylabel('Similitud semantica', fontsize=f_size)\n",
    "# plt.ylim(0,1)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FaITH measure\n",
    "\n",
    "Pirró & Euzenat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gloss Overlap\n",
    "plt.plot(Faith_rel, color='k', linestyle='None', marker='+', markersize=8, linewidth=1 )  \n",
    "plt.title('FaITH measure', fontsize=f_size)\n",
    "plt.xlabel('Numero de pareja', fontsize=f_size)\n",
    "#plt.ylabel('Similitud semantica', fontsize=f_size)\n",
    "# plt.ylim(0,1)\n",
    "plt.grid(True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
